%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,10pt]{acmart}

\usepackage{amsmath}
\usepackage{algorithm2e}

\SetKwRepeat{Struct}{struct \{}{\}}%
\newcommand{\Float}{\KwSty{float}}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmcopyright}
% \copyrightyear{2019}
% \acmYear{2019}
% \acmDOI{10.1145/1122445.1122456}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{PiTree: A Multidimensional Learned Index}


\author{Adam Jaffe}
\email{ajaffe@uwaterloo.ca}
\affiliation{
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
}


%% TODO
\author{Xiyeng Feng}
\email{x74feng@uwaterloo.ca}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
}



%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  This is my abstract, so it is not concrete yet. It cannot yet be used
  in the constructions of domiciles for human habitation.
  % TODO
\end{abstract}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

Analytical database engines store and process queries on large volumes of data.
Typically, in modern systems, this data is stored in memory. %TODO CITE
These systems scan and filter their data to execute queries.
Multidimensional range queries are a type of query defined by 
intervals in all or some of the columns and are interested in all data items
that are within all the given intervals. Multidimensional range queries that don't specify
an interval for at least one column are called partial range queries, while queries that specify
an interval for all dimensions are called complete range queries.
Multidimensional range queries are a common task for many applications.
For instance, they are used to query sensor data across a section of time and space, as well as in business
intelligence, scientific data and data science \cite{ModernMDRQ}.

With the explosion of analytical data comes the need to answer multidimensional range queries
quickly on large datasets. Multiple approaches have been taken to perform better than
fully scanning the dataset, which is quite wasteful if selectivity
of the query is low. If queries are very selective in one column, then sorting the data
according to that column and building a B-Tree can be a good approach. % TODO CITE
Another approach is to use a multidimensional index, which uses data from multiple dimensions
in its structure. Space filling curves, tree-based structures, and bucketing are three popular approaches
to build multidimensional indexes. Space filling curves, such as the Z-order or the Hilbert curve,
can be used to define an order on $n$-dimensional space, which can then be indexed using 
single-dimensional methods. % TODO cite Hilbert and Z-order
A complication of this approach is that points that are close in
n-dimensional space are not necessarily close together on the curve. % TODO Cite this
Tree-based structures can be though of as the multidimensional extension of B-Trees.
There are a variety methods that take this approach, such as R-Trees, kd-trees. % TODO Cite
Bucketing coarsely partitions the data space, which are then scanned and filtered to produce
the result set.
% TODO cite VA-file, grid file, locality sensitive hashing

In this paper we present PiTree, a learned multidimensional index designed for
in-memory multidimensional range queries capable of indexing
data of arbitrary dimension. PiTree extends in a natural way the recursive model index (RMI) strucutre
ideas from the original learned index paper to a multidimensional space.
Our main contributions are:
\begin{enumerate}
  \item The design and implementation from scratch of the PiTree multidimensaional learned index in C++
  % TODO highlight benchmark results
  \item A thorough evaluation of PiTree against an R*-Tree and kd-Tree 
  \item A discussion of future work to improve the performance of PiTree
\end{enumerate}

The rest of this report will be structured as follows. % TODO

\section{Background}

\subsection{Recursive Model Index}

The recent work by Kraska et al. on learned indexes
has cast the problem of single dimensional indexing in a new light \cite{Learned_Index}.
Their key insight is that given the empirical cumulative distribution function
of the dataset, in most cases, a very compact index can be constructed. 
The index structure they proposed is called the recursive model index (RMI) and they
demonstrated that it can take orders of magnitude less memory
than a classic B-tree while simultaneously providing similar throughput.

There are two key ideas behind RMI that made it so successful.
First is that overfitting is not an issue, unlike almost all other machine learning 
applications. In a non-dynamic indexing setting, the model does not need extrapolative
power, allowing more simple models to be used.
Second is that one complex model for the CDF is impractical due to large inference times
and memory size, and that a more fruitful approach is to 
use a hierarchy of models. The root model and internal models are used to route
to more specific models, which are trained on smaller segments of the dataset. 
Researches have tried different types of models in the hierarchy, including neural nets,
but the consensus seems to be that linear models perform the best due
to their small memory footprint and very quick inference time. % CITE learned index blog/argument, ALEX, etc.
Linear models are simply comprised of two floats $a$ and $b$ and inference
can be done with one multiplication, one addition, and an application of floor:
$y = \lfloor ax + b \rfloor$.

The leaf models in RMI are used to predict the location of the key in a sorted 
in-memory array. The prediction could be wrong, so a local search around the prediction
is required to find the key, if it exists. In order to speed up the searches,
a max error is maintained to be used for the bounds of the local search.
Since RMI is a clustered index, it is capable of performing single dimensional range searches
by simply finding the left endpoint range, then scanning to the right until reaching the right
endpoint.

% TODO diagram for RMI

\section{Single Dimensional Case}

\subsection{Motivation}
% TODO diagram for single dimension learned index

As described in Section 2, the main idea of single dimensional learned index is to replace
the traditional indexing structure like B-Tree with a machine learning model that is able
to learn the underlying data distribution. For point lookup, the learned index takes a key
as input and predicts the position of the key in the data layout. The prediction does not
necessarily to be exact as a quadratic search is introduced to correct the prediction error.

Theoretically, the point lookup time for single dimensional learned index equals to time
traversing the RMI plus time doing quadratic search. A model that can compute easily and predict
accurately is the key to speed up point lookup. However, there is usually a trade off between
model accuracy and computational cost in machine learning. For example, deep neural net is able
to model complex data distribution but is also extremely expensive to compute. On the other hand,
linear regression only involves one multiplication and one addition, but it only model linear
distributed data effectively. Kraska adopted linear regression based RMI in their single dimension
learned index mainly because the layout of single dimensional data is trivial such that it can be
effectively learned by linear models. However, such property may not hold for high dimensional cases.
Therefore, we think it worth first studying the trade off between model accuracy and model
computational cost. The result may guide us on the choice of models. 

\subsection{Experiment}

We implemented our single dimensional learned index with a two-stage RMI as proposed in 
Kraska's paper \cite{Learned_Index}. The two-stage RMI is configured to be able to accept
any model that takes a key as input and generates a position as output such that we can
plugin any machine learning model as needed. For simplicity, we only test on linear regression
model and neural net with one hidden layer that has eight hidden nodes. A native B-Tree with no optimization is also implemented
as the baseline. All indexing structures are implemented in Python as we do not care absolute
performance in single dimensional case as long as the comparison is fair and Python provides powerful
machine learning modules such as tensorflow. 

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
     & BTree & Linear Model & Neural Net \\
    \hline
    Avg lookup time(ms) & 8e-6 & 6e-5 & 1e-4 \\
    \hline 
    Avg prediction error & 0 & 0.35\% & 0.22\% \\
    \hline 
    Build time(s) & 0.17 & 24.21 & 80.46 \\
    \hline 
  \end{tabular}
  \caption{benchmark single dimensional learned index}
  \label{table:1}
\end{table}

We benmark our indexing structures on a random uniformly distributed single dimensional
dataset with 100 thousand data points. Each point is queried exactly once in the benchmark.
All tests are conducted under the same environment as described in Section 5.1. Table 1 shows
the benchmark results of BTree, linear model based RMI and neural net based RMI. Although
BTree appears to be the best indexing structure across all evaluation metrics, we believe the
overhead mainly comes from the tensorflow module as, later on when we finish implementing PiTree
and linear regression in C++, the performance is suprisingly good.

In terms of point lookup speed, neural net is about 20 times slower than linear regression model.
This is as expected since we are using a neural net with 1 hidden layer and 8 hidden nodes which
means for each prediction, neural net needs to do 16 linear regressions. Such high computational
overhead also brings an improvement on prediction accuracy. Neural net reduces the prediction
error (Average distance between prediction and actual position / Total data) by 0.13\%. However,
such improvement is negligible as it can be easily corrected by quadratic search. Model prediction
time becomes the dominant part in point lookup.

\subsection{Lessons Learned}

The success of single dimension learned index lies in the trivial data layout imposed by sorting.
Mispredictions can be effectively corrected without much scan overhead. However, such feature may
not exist in high dimensional cases. Points that are close in high dimensional space may be projected
far from each other in single dimensional space. Therefore, it is important to carefully design a
projection function which can preserve the relative position between points.

Since high dimensional data is more complex to learn, the choice of machien learning model also
worths discussion. Although neural net has been shown to be able to predict more accurately, its
large computational overhead is unaffordable. The model used in RMI does not necessarily need to
be very accurate but has to be easy to compute. Otherwise, traversing RMI will dominant the lookup.
The rationale behind this is simple. When it takes too much effort to correct the prediction, a better
approach is to simply leave the prediction as is while scanning everything in between. 

\section{PiTree Design}

PiTree is a multidimensional in-memory learned tree index structure for
mutlidimensional range queries. Currently, only complete range queries are supported.
Partial range queries are possible to support but are not included in this report. 
PiTree indexes a static dataset and does not support dynamic inserts, deletes,
although we believe it is possible to extend PiTree to allow dynamic inserts and deletes,
in the same way ALEX built upon the original RMI structure to achieve this functionality. % CITE ALEX

The datapoints, all of dimension $D$, are stored as one contiguous in-memory array.
Nodes in PiTree are comprised of a projection onto a single dimension, which it uses to
sort data points, and a linear regression model which models the CDF of a segment of the data.
Internal nodes use the linear model to select a child node to route to.
Leaf nodes use the linear model to find the relevant data point. 
PiTree is configurable with two parameters: the $pageSize$, 
which bounds the number of data points
a leaf node indexes, as well as $maxFanout$, which bounds the fanout
of an internal node.

\subsection{Node Structure}

\begin{algorithm}[t]
  \SetAlgoNoLine\PrintSemicolon
  \Struct{Node}{
    \KwSty{int} start,end\; 
    \KwSty{int} fanout\;
    \KwSty{Node *} children[]\;
    \KwSty{double} proj[]\;
    \KwSty{LinearModel} model\;
  }
  \caption{PiTree Node Strucutre}
  \label{PiTreeNode}
\end{algorithm}


Each node $n$ is responsible for indexing the range of the data array with indexes in $[start_n, end_n)$.
Nodes contain a projection vector $proj_n$ of the same dimension of the data
which it uses to sort the range of data it indexes. 
To be precise, if $d_1, d_2$ are two datapoints, the node will 
sort $d_1$ before $d_2$ if $d_1 \cdot proj_n < d_2 \cdot proj$.
PiTree uses a policy to select a projection on a per-node basis. In this report,
we only tested a policy which chooses a dimension to project onto in a round-robin
fashion, similar to how a kd-tree selects which dimension to split at each depth.
In particular, if a node is at depth $h$, then its
$D$ dimensional projection vector is the basis vector $e_{h \% D}$ that has components 
$$a_j = \begin{cases} 
  1 & j \equiv h \mod D \\
  0 & otherwise
\end{cases}
$$
for $j=1, \cdots, D$ and dimension $D$. Although for this report we only 
tested and implemented this round-robin policy because of time constraints,
we think there is potential
for more sophisticated policies and believe this to be a fruitful avenue of further
research.

Along with a projection, each node has a linear regression model 
to approximate the CDF of the data it indexes. If a node $n$ indexes data points
$data[start_n], data[start_n + 1], \cdots, data[end_n - 1]$ and has projection $proj_n$,
then for a number $k$, the
model approximates
\[ 
  \frac{|\{i \in [start_n, end_n) : data[i] \cdot proj_n < k\}|}{end - start},
\]

the portion of datapoints in the range that have a 
smaller projection than $k$.

The fanout for an internal node is $(end - start) / pageSize$, up to a maximum determined
by the parameter $maxFanout$. Internal nodes use the fanout along with the linear model
to determine which child node to route to.

\subsection{Constructing The Tree}

A PiTree is constructed from a static dataset in bulk loading process.
The tree is constructed recursively, with each node having a start and 
end index. The root is constructed with $start=0$ and $end=N$ where $N$
is the size of dataset. The base case is when $end - start \leq pageSize$,
in which case the node is a leaf.
First, use the projection policy to select a projection $proj$.
Second, construct a linear CDF model $M$ from the projections of the range of datapoints
the node indexes. If the node is leaf, stop. Otherwise,
compute the fanout 
\[
  f = \frac{end - start}{page\_size}.
\]

If $f > max\_fanout$, then set $f = max\_fanout$. This limits
the node from being too wide.
Then partition the interval $[start, end)$ into $f$ partitions
where the $i$-th partition 
\[
  P_i = \left\{j \in [start, end): \frac{i}{f} \leq M(proj \cdot d[j]) < \frac{i+1}{f} \right\}.
\]

Then the endpoints of each partition are used to recursively initialize child nodes.
If the model accurately represents the CDF of the data, which would be the case
if the data is nearly uniformly distributed under the projection,
it will be the case that each partition will have approximately the same number of
points $\frac{1}{f}$. The further from uniform the distribution becomes,
the less even the partitions will be.


\subsection{Point Search}

Although intended for multidimensional range queries,
PiTree can also handle point lookups. Understanding how point lookups
work will make it easier to understand how range queries

\subsection{Multidimensional Range Search}

\section{Evaluation}

This section first describes experiment setup together with baselines and datasets. 
Then we present the performance of PiTree compared with other state of the art 
indexing methods on different datasets followed by an in-depth evaluation. 
Overall the results show that:
\begin{itemize}
    \item TODO
\end{itemize}

\subsection{Experiment Setup}

All the tests are run on a Ubuntu 18.04 machine with 16 GB of memory and an Intel 
Core i7-6770HQ processor with 4 cores and 8 threads. PiTree and other indexing 
structures are implemented in C++ and compiled with optimization level -O3. 
All the data and indexing structures are stored in the memory so that no disk 
operation is involved in building indexing or executing queries.

\subsection{Baselines}

We compare PiTree to three other widely used multidimensional range query approaches 
named Full Scan, KD-Tree and R-Tree. Details about these baselines are listed 
as follow. 
\begin{itemize}
    \item \textbf{Full Scan}. Full Scan visits every point in the dataset and 
    compare every dimension appears in the query. This method is expected to have 
    the worst lookup time when the range queries are small. On the other hand, 
    when range queries are large enough that indexing structures are not able to 
    prune effectively, full scan should show a competitive performance.
    \item \textbf{KD-Tree}. KD-Tree is essentially a binary search tree that organizes
    points by partioning the K dimensional space. A non-leaf node will partition 
    the space into two parts and points are assigned accordingly. KD-Tree is easy to 
    implement but its effectiveness degrades for higher number of dimensions. Our KD-Tree is
    implemented in C++ from scratch and partition dimensions are selected in a round robin fashion.
    \item \textbf{R-Tree}. R-Tree is a depth-balanced tree that is widely used for spatial
    access method such as indexing geographical coordinates. We used a variant of R-Tree named
    R*-Tree which is optimized for better query performance. A bulk loading method is also 
    implemented to support testing on large dataset. We benchmarked the R*-Tree implementation
    provided by libspatialindex. % TODO add reference.

\end{itemize}

\subsection{Datasets}

Due to time constraints, we evaluate indexing structures only on synthetic datasets.

\subsection{Performance}

\subsection{Scalability}

\subsubsection{Query Selectivity}

\subsubsection{Dimension}

\subsection{Parameter Tuning}

\subsubsection{Max Fanout}

\subsubsection{Page Size}

\section{Related Work}

\section{Future Work}

\subsection{PCA}

\subsection{Cost Model}

\section{Conclusion}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
I'd like to thank my girlfriend Akshaya for always helping me when I need it.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}


\end{document}
\endinput
%%