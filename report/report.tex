%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.
\documentclass[sigconf,10pt]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2019}
\acmYear{2019}
\acmDOI{10.1145/1122445.1122456}


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{PiTree: A Multidimensional Learned Index}


\author{Adam Jaffe}
\email{ajaffe@uwaterloo.ca}
\affiliation{
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
}


%% TODO
\author{Xiyeng Feng}
\email{x74feng@uwaterloo.ca}
\affiliation{%
  \institution{University of Waterloo}
  \city{Waterloo}
  \state{Ontario}
}



%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  This is my abstract, so it is not concrete yet. It cannot yet be used
  in the constructions of domiciles for human habitation.
\end{abstract}


%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}

Analytical database engines store and process queries on large volumes of data.
Typically, in modern systems, this data is stored in memory. %TODO CITE
These systems scan and filter their data to execute queries.
Multidimensional range queries are a type of query defined by 
intervals in all or some of the columns and are interested in all data items
that are within all the given intervals. Multidimensional range queries that don't specify
an interval for at least one column are called partial range queries, while queries that specify
an interval for all dimensions are called complete range queries.
Multidimensional range queries are a common task for many applications.
For instance, they are used to query sensor data across a section of time and space, as well as in business
intelligence, scientific data and data science \cite{ModernMDRQ}.

With the explosion of analytical data comes the need to answer multidimensional range queries
quickly on large datasets. Multiple approaches have been taken to perform better than
fully scanning the dataset, which is quite wasteful if selectivity
of the query is low. If queries are very selective in one column, then sorting the data
according to that column and building a B-Tree can be a good approach. % TODO CITE
Another approach is to use a multidimensional index, which uses data from multiple dimensions
in its structure. Space filling curves, tree-based structures, and bucketing are three popular approaches
to build multidimensional indexes. Space filling curves, such as the Z-order or the Hilbert curve,
can be used to define an order on $n$-dimensional space, which can then be indexed using 
single-dimensional methods. % TODO cite Hilbert and Z-order
A complication of this approach is that points that are close in
n-dimensional space are not necessarily close together on the curve. % TODO Cite this
Tree-based structures can be though of as the multidimensional extension of B-Trees.
There are a variety methods that take this approach, such as R-Trees, kd-trees. % TODO Cite
Bucketing coarsely partitions the data space, which are then scanned and filtered to produce
the result set.
% TODO cite VA-file, grid file, locality sensitive hashing

In this paper we present PiTree, a learned multidimensional index designed for
in-memory multidimensional range queries. PiTree extends in a natural way the recursive model index (RMI) strucutre
ideas from the original learned index paper to a multidimensional space.
Our main contributions are:
\begin{enumerate}
  \item The design and implementation from scratch of the PiTree multidimensaional learned index in C++
  % TODO highlight benchmark results
  \item A thorough evaluation of PiTree against an R*-Tree and kd-Tree 
  \item A discussion of future work to improve the performance of PiTree
\end{enumerate}

The rest of this report will be structured as follows. % TODO

\section{Background}

\subsection{Recursive Model Index}

The recent work by Kraska et al. on learned indexes
has cast the problem of single dimensional indexing in a new light \cite{Learned_Index}.
Their key insight is that given the empirical cumulative distribution function
of the dataset, in most cases, a very compact index can be constructed. 
The index structure they proposed is called the recursive model index (RMI) and they
demonstrated that it can take orders of magnitude less memory
than a classic B-tree while simultaneously providing similar throughput.

There are two key ideas behind RMI that made it so successful.
First is that overfitting is not an issue, unlike almost all other machine learning 
applications. In a non-dynamic indexing setting, the model does not need to have extrapolative
power and more simple models can be used.
Second is that one large model for the CDF is impractical due to the latency in evaluation
and size, and that a more fruitful approach is to 
use a hierarchy of models. The root model and internal models are used to route
to more specific models, which are trained on smaller sections of the dataset. 
Many different types of models have been used in the hierarchy, including neural nets,
but researches have determined that linear models perform the best due
to their small size and very quick inference time. % CITE learned index blog/argument, ALEX, etc.
Linear models can be simply be comprised of two floats $a$ and $b$ and inference
can be done with one multiplication, one addition, and an application of floor:
$y = \lfloor ax + b \rfloor$.

The leaf models in RMI are used to predict the location of the key in a sorted 
in-memory array. The prediction could be wrong, so a local search around the prediction
is required to find the key, if it exists. In order to speed up the searches,
a max error is maintained to be used for the bounds of the local search.

% TODO diagram for RMI

\section{Single Dimensional Case}

% Xiyeng TODO

\section{PiTree Design}

\subsection{Tree Structure}

\subsection{Refinement}

\section{Evaluation}

This section first describes experiment setup together with baselines and datasets. Then we present the performance of PiTree compared with other state of the art indexing methods on different datasets followed by an in-depth evaluation. Overall the results show that:
\begin{itemize}
    \item TODO
\end{itemize}

\subsection{Experiment Setup}

All the tests are run on a Ubuntu 18.04 machine with 16 GB of memory and an Intel Core i7-6770HQ processor with 4 cores and 8 threads. PiTree and other indexing structures are implemented in C++ and compiled with optimization level -O3. All the data and indexing structures are stored in the memory so that no disk operation is involved in building indexing or executing queries.

\subsection{Baselines}

We compare PiTree to three other widely used multidimensional range query approaches named Full Scan, KD-Tree and R-Tree. Details about these baselines are listed as follow. 
\begin{itemize}
    \item \textbf{Full Scan}. Full Scan visits every point in the dataset and compare every dimension appears in the query. This method is expected to have the worst lookup time when the range queries are small. On the other hand, when range queries are large enough that indexing structures are not able to prune effectively, full scan should show a competitive performance.
    \item \textbf{KD-Tree}. KD-Tree is essentially a binary search tree 
    \item \textbf{R-Tree}
\end{itemize}

\subsection{Datasets}

\section{Related Work}

\section{Future Work}

\subsection{PCA}

\subsection{Cost Model}

\section{Conclusion}

%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
I'd like to thank my girlfriend Akshaya for always helping me when I need it.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{refs}


\end{document}
\endinput
%%